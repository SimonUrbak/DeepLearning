{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIM_rnsJ-UiL",
        "outputId": "7e020089-9e72-45a4-b825-3c8052b30146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scmap\n",
            "  Downloading scmap-0.1.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: scmap\n",
            "Successfully installed scmap-0.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install scmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x2hQSar5KYB",
        "outputId": "4ea5d0e9-21c8-4d36-c1f5-764fd2eb9129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting structure-tensor\n",
            "  Downloading structure-tensor-0.2.0.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from structure-tensor) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.8/dist-packages (from structure-tensor) (1.7.3)\n",
            "Building wheels for collected packages: structure-tensor\n",
            "  Building wheel for structure-tensor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for structure-tensor: filename=structure_tensor-0.2.0-py3-none-any.whl size=15924 sha256=0bc4a7d4bbe1cf9751cf242897cdd5283793f0d50a9e7b82c5a191ac04abca5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/20/c3/7f70390148b5bd4ca9efcdd82ba1c678e7d26194a1c4d9401d\n",
            "Successfully built structure-tensor\n",
            "Installing collected packages: structure-tensor\n",
            "Successfully installed structure-tensor-0.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install structure-tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvhuP1LV4UP7",
        "outputId": "62823dda-9f8a-4619-c22f-ce590101ddbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Could not load CuPy: cannot import name 'filters' from 'cupyx.scipy.ndimage' (/usr/local/lib/python3.8/dist-packages/cupyx/scipy/ndimage/__init__.py)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import skimage.io\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/NyDLProjekt')\n",
        "\n",
        "from structure_tensor import eig_special_3d, structure_tensor_3d\n",
        "from data_funcs import DataPrepAndSave, CreateDataLoaders\n",
        "from sympy import *\n",
        "import numpy as np\n",
        "from numpy import arctan2, sqrt\n",
        "import numexpr as ne\n",
        "\n",
        "\n",
        "def cords2angles(y):\n",
        "    batch_size,c,height,width,depth = y.shape\n",
        "    theta = torch.empty([batch_size,2,height,width,depth])\n",
        "    theta = theta.cuda()\n",
        "    theta[:,0,:,:,:] = torch.arctan2(y[:,1,:,:,:], y[:,0,:,:,:])\n",
        "    theta[:,1,:,:,:] = torch.arctan2(torch.sqrt(y[:,0,:,:,:]**2+y[:,1,:,:,:]**2), y[:,2,:,:,:])\n",
        "    return theta\n",
        "\n",
        "def angles2cords(theta):\n",
        "    batch_size,c,height,width,depth = theta.shape\n",
        "    ynew = torch.empty([batch_size,3,height,width,depth])\n",
        "    ynew = ynew.cuda()\n",
        "    ynew[:,0,:,:,:] = torch.cos(theta[:,0,:,:,:]) * torch.sin(theta[:,1,:,:,:])#x\n",
        "    ynew[:,1,:,:,:] = torch.sin(theta[:,1,:,:,:]) * torch.sin(theta[:,0,:,:,:]) #y\n",
        "    ynew[:,2,:,:,:] = torch.cos(theta[:,1,:,:,:]) #z\n",
        "    return ynew\n",
        "\n",
        "def anglediff(y,y1):\n",
        "    delta = 2*(1-torch.cos(y1-y))\n",
        "    return torch.mean(delta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhRcKOuE26Fb"
      },
      "outputs": [],
      "source": [
        "class Net_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_1, self).__init__()\n",
        "        self.out1 = 6*2\n",
        "        self.out2 = 12*2\n",
        "        self.out3 = 24*2\n",
        "        self.out4 = 48*2\n",
        "        self.out5 = 96*2\n",
        "\n",
        "\n",
        "        self.kernel_size = 3\n",
        "        self.padding = 1\n",
        "\n",
        "\n",
        "        #StructureTensorPart\n",
        "        self.up = nn.Upsample(scale_factor = 2, mode = 'trilinear',align_corners=True)\n",
        "        self.down = nn.Upsample(scale_factor = 1/2,mode = 'trilinear',align_corners=True)\n",
        "        self.down2 = nn.Upsample(scale_factor = 24/25,mode = 'trilinear',align_corners=True)\n",
        "        self.S_conv1 = nn.Conv3d(in_channels = 3, out_channels = self.out1, kernel_size = self.kernel_size, padding = 0 )\n",
        "        self.S_conv2 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm1S = nn.BatchNorm3d(self.out1)\n",
        "        self.S_mp1 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv3 = nn.Conv3d(in_channels = self.out1, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.S_conv4 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm2S = nn.BatchNorm3d(self.out2)\n",
        "\n",
        "        self.S_mp2 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv5 = nn.Conv3d(in_channels = self.out2, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv6 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm3S = nn.BatchNorm3d(self.out3)\n",
        "\n",
        "        self.S_mp3 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv7 = nn.Conv3d(in_channels = self.out3, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "\n",
        "        self.Batchnorm4S = nn.BatchNorm3d(self.out4)\n",
        "        self.S_mp4 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv9 = nn.Conv3d(in_channels = self.out4, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv10 = nn.Conv3d(in_channels = self.out5, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        \n",
        "\n",
        "\n",
        "        #FullImagePart\n",
        "        self.I_conv1 = nn.Conv3d(in_channels = 1, out_channels = self.out1, kernel_size = self.kernel_size, padding = 0 )\n",
        "        self.I_conv2 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm1I = nn.BatchNorm3d(self.out1)\n",
        "\n",
        "        self.I_mp1 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv3 = nn.Conv3d(in_channels = self.out1, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.I_conv4 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm2I = nn.BatchNorm3d(self.out2)\n",
        "        self.I_mp2 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv5 = nn.Conv3d(in_channels = self.out2, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv6 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm3I = nn.BatchNorm3d(self.out3)\n",
        "        self.I_mp3 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv7 = nn.Conv3d(in_channels = self.out3, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm4I = nn.BatchNorm3d(self.out4)\n",
        "        self.I_mp4 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv9 = nn.Conv3d(in_channels = self.out4, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv10 = nn.Conv3d(in_channels = self.out5, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        #Combining part\n",
        "\n",
        "        self.convST1 = nn.ConvTranspose3d(in_channels = self.out5, out_channels = self.out4,kernel_size = 2, stride = 2)\n",
        "        self.convIT1 = nn.ConvTranspose3d(in_channels = self.out5, out_channels = self.out4,kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv7 = nn.Conv3d(in_channels = 4*self.out4, out_channels = self.out4, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        \n",
        "        self.convT2 = nn.ConvTranspose3d(in_channels = self.out4, out_channels = self.out3,kernel_size = 2,stride = 2)\n",
        "\n",
        "\n",
        "        self.conv9 = nn.Conv3d(in_channels = 3 * self.out3, out_channels = self.out3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv10 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT3 = nn.ConvTranspose3d(in_channels = self.out3, out_channels = self.out2, kernel_size = 2, stride = 2)\n",
        "        \n",
        "        self.conv11 = nn.Conv3d(in_channels = 3 * self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv12 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT4 = nn.ConvTranspose3d(in_channels = self.out2, out_channels = self.out1,kernel_size = 2,stride = 2)\n",
        "        self.convT5 = nn.ConvTranspose3d(in_channels = 3*self.out1, out_channels = self.out1, kernel_size =self.kernel_size, stride = 1, padding = 0)\n",
        "        \n",
        "        self.conv13 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv14 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "\n",
        "        self.conv15 = nn.Conv3d(in_channels = self.out1, out_channels = 3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "\n",
        "\n",
        "    def st_vec(self, x, scale):\n",
        "      X = torch.zeros([batch_size,3,int(height*scale),int(width*scale),int(depth*scale)])\n",
        "      X.cuda()\n",
        "      for b in range(batch_size):\n",
        "          s = structure_tensor_3d(x[b,0,:,:,:],1/2,1)\n",
        "          val,vec = eig_special_3d(s)\n",
        "          X[b,:,:,:,:] = torch.Tensor(vec)\n",
        "      return X\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "       xstruct = self.down(x)\n",
        "       s2 = self.st_vec(xstruct, scale)\n",
        "       s1 = self.up(s2)\n",
        "       u1 = F.normalize(s1)\n",
        "       return s1\n",
        "\n",
        "\n",
        "class Net_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_2, self).__init__()\n",
        "        self.out1 = 6*2\n",
        "        self.out2 = 12*2\n",
        "        self.out3 = 24*2\n",
        "        self.out4 = 48*2\n",
        "        self.out5 = 96*2\n",
        "\n",
        "\n",
        "        self.kernel_size = 3\n",
        "        self.padding = 1\n",
        "\n",
        "\n",
        "        #StructureTensorPart\n",
        "        self.up = nn.Upsample(scale_factor = 2, mode = 'trilinear',align_corners=True)\n",
        "        self.down = nn.Upsample(scale_factor = 1/2,mode = 'trilinear',align_corners=True)\n",
        "        self.down2 = nn.Upsample(scale_factor = 24/25,mode = 'trilinear',align_corners=True)\n",
        "        self.S_conv1 = nn.Conv3d(in_channels = 3, out_channels = self.out1, kernel_size = self.kernel_size, padding = 0 )\n",
        "        self.S_conv2 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm1S = nn.BatchNorm3d(self.out1)\n",
        "        self.S_mp1 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv3 = nn.Conv3d(in_channels = self.out1, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.S_conv4 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm2S = nn.BatchNorm3d(self.out2)\n",
        "\n",
        "        self.S_mp2 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv5 = nn.Conv3d(in_channels = self.out2, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv6 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm3S = nn.BatchNorm3d(self.out3)\n",
        "\n",
        "        self.S_mp3 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv7 = nn.Conv3d(in_channels = self.out3, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "\n",
        "        self.Batchnorm4S = nn.BatchNorm3d(self.out4)\n",
        "        self.S_mp4 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_conv9 = nn.Conv3d(in_channels = self.out4, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv10 = nn.Conv3d(in_channels = self.out5, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        \n",
        "\n",
        "\n",
        "        #FullImagePart\n",
        "        self.I_conv1 = nn.Conv3d(in_channels = 1, out_channels = self.out1, kernel_size = self.kernel_size, padding = 0 )\n",
        "        self.I_conv2 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm1I = nn.BatchNorm3d(self.out1)\n",
        "\n",
        "        self.I_mp1 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv3 = nn.Conv3d(in_channels = self.out1, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.I_conv4 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm2I = nn.BatchNorm3d(self.out2)\n",
        "        self.I_mp2 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv5 = nn.Conv3d(in_channels = self.out2, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv6 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm3I = nn.BatchNorm3d(self.out3)\n",
        "        self.I_mp3 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv7 = nn.Conv3d(in_channels = self.out3, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.Batchnorm4I = nn.BatchNorm3d(self.out4)\n",
        "        self.I_mp4 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_conv9 = nn.Conv3d(in_channels = self.out4, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv10 = nn.Conv3d(in_channels = self.out5, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        #Combining part\n",
        "\n",
        "        self.convST1 = nn.ConvTranspose3d(in_channels = self.out5, out_channels = self.out4,kernel_size = 2, stride = 2)\n",
        "        self.convIT1 = nn.ConvTranspose3d(in_channels = self.out5, out_channels = self.out4,kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv7 = nn.Conv3d(in_channels = 4*self.out4, out_channels = self.out4, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        \n",
        "        self.convT2 = nn.ConvTranspose3d(in_channels = self.out4, out_channels = self.out3,kernel_size = 2,stride = 2)\n",
        "\n",
        "\n",
        "        self.conv9 = nn.Conv3d(in_channels = 3 * self.out3, out_channels = self.out3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv10 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT3 = nn.ConvTranspose3d(in_channels = self.out3, out_channels = self.out2, kernel_size = 2, stride = 2)\n",
        "        \n",
        "        self.conv11 = nn.Conv3d(in_channels = 3 * self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv12 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT4 = nn.ConvTranspose3d(in_channels = self.out2, out_channels = self.out1,kernel_size = 2,stride = 2)\n",
        "        self.convT5 = nn.ConvTranspose3d(in_channels = 3*self.out1, out_channels = self.out1, kernel_size =self.kernel_size, stride = 1, padding = 0)\n",
        "        \n",
        "        self.conv13 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv14 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "\n",
        "        self.conv15 = nn.Conv3d(in_channels = self.out1, out_channels = 3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "\n",
        "\n",
        "    def st_vec(self, x, scale):\n",
        "      X = torch.zeros([batch_size,3,int(height*scale),int(width*scale),int(depth*scale)])\n",
        "      X.cuda()\n",
        "      for b in range(batch_size):\n",
        "          s = structure_tensor_3d(x[b,0,:,:,:],1/2,1)\n",
        "          val,vec = eig_special_3d(s)\n",
        "          X[b,:,:,:,:] = torch.Tensor(vec)\n",
        "      return X\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "       xstruct = self.down(x)\n",
        "       s2 = self.st_vec(xstruct, scale)\n",
        "       s1 = self.up(s2)\n",
        "       s1 = s1.cuda()\n",
        "       s2 = self.down2(s2)\n",
        "       x = x.cuda()\n",
        "      \n",
        "       i1 = F.relu(self.I_conv1(x))\n",
        "       s1 = F.relu(self.S_conv1(s1))\n",
        "       i1 = F.relu(self.I_conv2(i1))\n",
        "       i2 = self.Batchnorm1I(i1)\n",
        "       s1 = F.relu(self.S_conv2(s1))\n",
        "       s2 = self.Batchnorm1S(s1)\n",
        "       i2 = self.I_mp1(i2)\n",
        "       s2 = self.I_mp1(s2)\n",
        "\n",
        "\n",
        "       i2 = F.relu(self.I_conv3(i2))\n",
        "       s2 = F.relu(self.S_conv3(s2))\n",
        "       i2 = F.relu(self.I_conv4(i2))\n",
        "       s2 = F.relu(self.S_conv4(s2))\n",
        "       i3 = self.Batchnorm2I(i2)\n",
        "       s3 = self.Batchnorm2S(s2)\n",
        "       i3 = self.I_mp2(i3)\n",
        "       s3 = self.S_mp2(s3)\n",
        "\n",
        "       i3 = F.relu(self.I_conv5(i3))\n",
        "       s3 = F.relu(self.S_conv5(s3))\n",
        "       i3 = F.relu(self.I_conv6(i3))\n",
        "       i4 = self.Batchnorm3I(i3)\n",
        "       s3 = F.relu(self.S_conv6(s3))\n",
        "       s4 = self.Batchnorm3S(s3)\n",
        "       i4 = self.I_mp3(i4)\n",
        "       s4 = self.S_mp3(s4)\n",
        "\n",
        "       i4 = F.relu(self.I_conv7(i4))\n",
        "       s4 = F.relu(self.S_conv7(s4))\n",
        "       i4 = F.relu(self.I_conv8(i4))\n",
        "       s4 = F.relu(self.S_conv8(s4))\n",
        "       s5 = self.Batchnorm4S(s4)\n",
        "       i5 = self.Batchnorm4I(i4)\n",
        "       i5 = self.I_mp4(i5)\n",
        "       s5 = self.S_mp4(s5)\n",
        "\n",
        "       \n",
        "       i5 = F.relu(self.I_conv9(i5))\n",
        "       s5 = F.relu(self.S_conv9(s5))\n",
        "       i5 = F.relu(self.I_conv10(i5))\n",
        "       s5 = F.relu(self.S_conv10(s5))\n",
        "\n",
        "       \n",
        "\n",
        "       uI4 = self.convIT1(i5)\n",
        "       uS4 = self.convST1(s5)\n",
        "\n",
        "       u4 = torch.cat((uI4,uS4, i4, s4),dim = 1)\n",
        "       u4 = F.relu(self.conv7(u4))\n",
        "       u4 = F.relu(self.conv8(u4))\n",
        "       u3 = self.convT2(i4)\n",
        "       u3 = torch.cat((u3,i3, s3),dim = 1)\n",
        "       u3 = F.relu(self.conv9(u3))\n",
        "       u3 = F.relu(self.conv10(u3))\n",
        "       u2 = self.convT3(u3)\n",
        "       u2 = torch.cat((u2,s2,i2),dim = 1)\n",
        "       u2 = F.relu(self.conv11(u2))\n",
        "       u2 = F.relu(self.conv12(u2))\n",
        "       u1 = self.convT4(u2)\n",
        "       u1 = torch.cat((u1,s1,i1), dim= 1)\n",
        "       u1 = self.convT5(u1)\n",
        "       u1 = F.relu(self.conv13(u1))\n",
        "       u1 = F.relu(self.conv14(u1))\n",
        "       u1 = self.conv15(u1)\n",
        "       u1 = F.normalize(u1)\n",
        "       return u1\n",
        "\n",
        "\n",
        "class Net_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_3, self).__init__()\n",
        "        self.out1 = 6*2\n",
        "        self.out2 = 12*2\n",
        "        self.out3 = 24*2\n",
        "        self.out4 = 48*2\n",
        "        self.out5 = 96*2\n",
        "\n",
        "\n",
        "        self.kernel_size = 3\n",
        "        self.padding = 1\n",
        "\n",
        "\n",
        "        #StructureTensorPart\n",
        "        self.up = nn.Upsample(scale_factor = 2, mode = 'trilinear',align_corners=True)\n",
        "        self.down = nn.Upsample(scale_factor = 1/2,mode = 'trilinear',align_corners=True)\n",
        "        self.down2 = nn.Upsample(scale_factor = 24/25,mode = 'trilinear',align_corners=True)\n",
        "        self.S_conv1 = nn.Conv3d(in_channels = 2, out_channels = self.out1, kernel_size = self.kernel_size, padding = 0 )\n",
        "        self.S_conv2 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.S_mp1 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_bn1 = nn.BatchNorm3d(self.out1)\n",
        "        self.S_conv3 = nn.Conv3d(in_channels = self.out1, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.S_conv4 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.S_mp2 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_bn2 = nn.BatchNorm3d(self.out2)\n",
        "        self.S_conv5 = nn.Conv3d(in_channels = self.out2, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv6 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_mp3 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_bn3 = nn.BatchNorm3d(self.out3)\n",
        "        self.S_conv7 = nn.Conv3d(in_channels = self.out3, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_mp4 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.S_bn4 = nn.BatchNorm3d(self.out4)\n",
        "        self.S_conv9 = nn.Conv3d(in_channels = self.out4, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.S_conv10 = nn.Conv3d(in_channels = self.out5, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        \n",
        "\n",
        "\n",
        "        #FullImagePart\n",
        "        self.I_conv1 = nn.Conv3d(in_channels = 1, out_channels = self.out1, kernel_size = self.kernel_size, padding = 0 )\n",
        "        self.I_conv2 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.I_mp1 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_bn1 = nn.BatchNorm3d(self.out1)\n",
        "        self.I_conv3 = nn.Conv3d(in_channels = self.out1, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.I_conv4 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.I_mp2 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_bn2 = nn.BatchNorm3d(self.out2)\n",
        "        self.I_conv5 = nn.Conv3d(in_channels = self.out2, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv6 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_mp3 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_bn3 = nn.BatchNorm3d(self.out3)\n",
        "        self.I_conv7 = nn.Conv3d(in_channels = self.out3, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_mp4 = nn.MaxPool3d(kernel_size = 2)\n",
        "        self.I_bn4 = nn.BatchNorm3d(self.out4)\n",
        "        self.I_conv9 = nn.Conv3d(in_channels = self.out4, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        self.I_conv10 = nn.Conv3d(in_channels = self.out5, out_channels = self.out5, kernel_size = self.kernel_size, padding = self.padding)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        #Combining part\n",
        "\n",
        "        self.convST1 = nn.ConvTranspose3d(in_channels = self.out5, out_channels = self.out4,kernel_size = 2, stride = 2)\n",
        "        self.convIT1 = nn.ConvTranspose3d(in_channels = self.out5, out_channels = self.out4,kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv7 = nn.Conv3d(in_channels = 4*self.out4, out_channels = self.out4, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv8 = nn.Conv3d(in_channels = self.out4, out_channels = self.out4, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT2 = nn.ConvTranspose3d(in_channels = self.out4, out_channels = self.out3,kernel_size = 2,stride = 2)\n",
        "\n",
        "\n",
        "        self.conv9 = nn.Conv3d(in_channels = 3 * self.out3, out_channels = self.out3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv10 = nn.Conv3d(in_channels = self.out3, out_channels = self.out3, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT3 = nn.ConvTranspose3d(in_channels = self.out3, out_channels = self.out2, kernel_size = 2, stride = 2)\n",
        "        \n",
        "        self.conv11 = nn.Conv3d(in_channels = 3 * self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv12 = nn.Conv3d(in_channels = self.out2, out_channels = self.out2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        \n",
        "        self.convT4 = nn.ConvTranspose3d(in_channels = self.out2, out_channels = self.out1,kernel_size = 2,stride = 2)\n",
        "        self.convT5 = nn.ConvTranspose3d(in_channels = 3*self.out1, out_channels = self.out1, kernel_size =self.kernel_size, stride = 1, padding = 0)\n",
        "        \n",
        "        self.conv13 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "        self.conv14 = nn.Conv3d(in_channels = self.out1, out_channels = self.out1, kernel_size =self.kernel_size, padding = self.padding)\n",
        "\n",
        "        self.conv15 = nn.Conv3d(in_channels = self.out1, out_channels = 2, kernel_size =self.kernel_size, padding = self.padding)\n",
        "    def st_vec(self, x, scale):\n",
        "      X = torch.zeros([batch_size,3,int(height*scale),int(width*scale),int(depth*scale)])\n",
        "      X.cuda()\n",
        "      for b in range(batch_size):\n",
        "          s = structure_tensor_3d(x[b,0,:,:,:],1/2,1)\n",
        "          val,vec = eig_special_3d(s)\n",
        "          X[b,:,:,:,:] = torch.Tensor(vec)\n",
        "      return X\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "       xstruct = self.down(x)\n",
        "       s2 = self.st_vec(xstruct, scale)\n",
        "       s1 = self.up(s2)\n",
        "       s1 = cords2angles(s1)\n",
        "       x = x.cuda()\n",
        "      \n",
        "       i1 = F.relu(self.I_conv1(x))\n",
        "       s1 = F.relu(self.S_conv1(s1))\n",
        "       i1 = F.relu(self.I_conv2(i1))\n",
        "       s1 = F.relu(self.S_conv2(s1))\n",
        "       i2 = self.I_bn1(i1)\n",
        "       s2 = self.S_bn1(s1)\n",
        "       i2 = self.I_mp1(i2)\n",
        "       s2 = self.S_mp1(s2)\n",
        "\n",
        "\n",
        "       i2 = F.relu(self.I_conv3(i2))\n",
        "       s2 = F.relu(self.S_conv3(s2))\n",
        "       i2 = F.relu(self.I_conv4(i2))\n",
        "       s2 = F.relu(self.S_conv4(s2))\n",
        "       i3 = self.I_bn2(i2)\n",
        "       s3 = self.S_bn2(s2)\n",
        "       i3 = self.I_mp2(i3)\n",
        "       s3 = self.S_mp2(s3)\n",
        "\n",
        "       i3 = F.relu(self.I_conv5(s3))\n",
        "       s3 = F.relu(self.S_conv5(s3))\n",
        "       i3 = F.relu(self.I_conv6(i3))\n",
        "       s3 = F.relu(self.S_conv6(s3))\n",
        "       i4 = self.I_bn3(i3)\n",
        "       s4 = self.S_bn3(s3)\n",
        "       i4 = self.I_mp3(i4)\n",
        "       s4 = self.S_mp3(s4)\n",
        "\n",
        "       i4 = F.relu(self.I_conv7(i4))\n",
        "       s4 = F.relu(self.S_conv7(s4))\n",
        "       i4 = F.relu(self.I_conv8(i4))\n",
        "       s4 = F.relu(self.S_conv8(s4))\n",
        "       i5 = self.I_bn4(i4)\n",
        "       s5 = self.S_bn4(s4)\n",
        "       i5 = self.I_mp4(i5)\n",
        "       s5 = self.S_mp4(s5)\n",
        "\n",
        "       \n",
        "       i5 = F.relu(self.I_conv9(i5))\n",
        "       s5 = F.relu(self.S_conv9(s5))\n",
        "       i5 = F.relu(self.I_conv10(i5))\n",
        "       s5 = F.relu(self.S_conv10(s5))\n",
        "\n",
        "       \n",
        "\n",
        "       uI4 = self.convIT1(i5)\n",
        "       uS4 = self.convST1(s5)\n",
        "\n",
        "\n",
        "\n",
        "       u4 = torch.cat((uI4,uS4, i4, s4),dim = 1)\n",
        "       u4 = F.relu(self.conv7(u4))\n",
        "       u4 = F.relu(self.conv8(u4))\n",
        "       u3 = self.convT2(i4)\n",
        "       u3 = torch.cat((u3,i3, s3),dim = 1)\n",
        "       u3 = F.relu(self.conv9(u3))\n",
        "       u3 = F.relu(self.conv10(u3))\n",
        "       u2 = self.convT3(u3)\n",
        "       u2 = torch.cat((u2,s2,i2),dim = 1)\n",
        "       u2 = F.relu(self.conv11(u2))\n",
        "       u2 = F.relu(self.conv12(u2))\n",
        "       u1 = self.convT4(u2)\n",
        "       u1 = torch.cat((u1,s1,i1), dim= 1)\n",
        "       u1 = self.convT5(u1)\n",
        "       u1 = F.relu(self.conv13(u1))\n",
        "       u1 = F.relu(self.conv14(u1))\n",
        "       u1 = torch.tanh(self.conv15(u1))*torch.pi\n",
        "\n",
        "       #u1 = F.normalize(self.conv11(u1),dim = 1)\n",
        "       return u1  \n",
        "   \n",
        "class Net_Tri_norm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_Tri_norm, self).__init__()\n",
        "        self.up = nn.Upsample(scale_factor = 2, mode = 'trilinear',align_corners=True)\n",
        "        self.down = nn.Upsample(scale_factor = 1/2,mode = 'trilinear',align_corners=True)\n",
        "    def st_vec(self,x):\n",
        "     X = torch.zeros([batch_size,3,int(height*scale),int(width*scale),int(depth*scale)])\n",
        "     for b in range(batch_size):\n",
        "         s = structure_tensor_3d(x[b,0,:,:,:],1/2,1)\n",
        "         val,vec = eig_special_3d(s)\n",
        "         X[b,:,:,:,:] = torch.Tensor(vec)\n",
        "     return X\n",
        "    def forward(self, x):\n",
        "\n",
        "       x = self.down(x)\n",
        "\n",
        "       x = self.st_vec(x)\n",
        "\n",
        "       x = self.up(x)\n",
        "\n",
        "       x = F.normalize(x,dim = 1)\n",
        "       return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9CIbgk23skP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5700ab0b-4e35-403f-8d35-e12e1489d7ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net_3(\n",
              "  (up): Upsample(scale_factor=2.0, mode=trilinear)\n",
              "  (down): Upsample(scale_factor=0.5, mode=trilinear)\n",
              "  (down2): Upsample(scale_factor=0.96, mode=trilinear)\n",
              "  (S_conv1): Conv3d(2, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "  (S_conv2): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_mp1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (S_bn1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (S_conv3): Conv3d(12, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_conv4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_mp2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (S_bn2): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (S_conv5): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_conv6): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_mp3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (S_bn3): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (S_conv7): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_conv8): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_mp4): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (S_bn4): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (S_conv9): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (S_conv10): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_conv1): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "  (I_conv2): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_mp1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (I_bn1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (I_conv3): Conv3d(12, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_conv4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_mp2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (I_bn2): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (I_conv5): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_conv6): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_mp3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (I_bn3): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (I_conv7): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_conv8): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_mp4): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (I_bn4): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (I_conv9): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (I_conv10): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (convST1): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (convIT1): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (conv7): Conv3d(384, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv8): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (convT2): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (conv9): Conv3d(144, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv10): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (convT3): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (conv11): Conv3d(72, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv12): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (convT4): ConvTranspose3d(24, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "  (convT5): ConvTranspose3d(36, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "  (conv13): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv14): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv15): Conv3d(12, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "modelinterpolation = Net_1()\n",
        "modelinterpolation.eval()\n",
        "modelinterpolation.cuda() \n",
        "modelcartesian = Net_2()\n",
        "modelcartesian.load_state_dict(torch.load('CarthTRAINED-1.pt'))\n",
        "modelcartesian.eval()\n",
        "modelcartesian.cuda()\n",
        "\n",
        "modelpolar = Net_3()\n",
        "modelpolar.load_state_dict(torch.load('polarTRAINED_new2.pt'))\n",
        "modelpolar.eval()\n",
        "modelpolar.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKwS-LpA9uxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "10b458dc-9572-4965-8069-818107db679e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-dc3f25865b17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreateDataLoaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-dc3f25865b17>\u001b[0m in \u001b[0;36mCreateDataLoaders\u001b[0;34m(split_ratios, batch_size, single)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rockwool_1_X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rockwool_1_Y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    441\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def CreateDataLoaders(split_ratios = [0.9,0.1],batch_size = 4,single = False):\n",
        "    '''\n",
        "    Loads saved the saved dataset, and returns dataloaders for the train, test\n",
        "    and validation sets. Takes the parameter split_ratios for the data split,\n",
        "    and batch_size to control batch size\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    if sum(split_ratios) != 1:\n",
        "        print(\"Sum of split_ratios must be 1!\")\n",
        "        raise ValueError\n",
        "    \n",
        "    X = np.load('rockwool_1_X.npy')\n",
        "    Y = np.load('rockwool_1_Y.npy')\n",
        "    \n",
        "    #X = np.concatenate((X,X_2),axis = 0)  \n",
        "    #Y = np.concatenate((Y,Y_2),axis = 0)\n",
        "    nTraining,_,_,_ = X.shape\n",
        "    tensor_y = torch.Tensor(Y)\n",
        "    tensor_x = torch.Tensor(X)\n",
        "\n",
        "    #tensor_precomp = torch.Tensor(precomp)\n",
        "    my_dataset = TensorDataset(tensor_x,tensor_y)\n",
        "    if single == True:\n",
        "        return DataLoader(my_dataset, batch_size)\n",
        "    \n",
        "    # the data splitter needs lengths not ratios so we convert \n",
        "    lengths = [int(nTraining*split_ratios[i]) for i in range(2)]\n",
        "    lengths[0] += nTraining - sum(lengths) \n",
        "    \n",
        "    \n",
        "    train,val = torch.utils.data.random_split(my_dataset,lengths,generator=torch.Generator().manual_seed(42))\n",
        "    train = DataLoader(train, batch_size,shuffle = True)\n",
        "    val = DataLoader(val, batch_size,shuffle = True)\n",
        "    return train, val\n",
        "scale = 0.5\n",
        "height = width = depth = 50\n",
        "batch_size = 16\n",
        "dl = CreateDataLoaders(single = True,batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1P5q3jp8mqF",
        "outputId": "8a3053cc-a922-4b14-e416-b7146fc72287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 64/64 [00:55<00:00,  1.15it/s]\n"
          ]
        }
      ],
      "source": [
        "height = width = depth = 50\n",
        "criterion = nn.MSELoss()\n",
        "# MSE and Time for \n",
        "\n",
        "Tinter = 0\n",
        "Tinter1 = 0\n",
        "\n",
        "Tstruct = 0\n",
        "Tcart = 0\n",
        "Tpol = 0\n",
        "for Data in tqdm(dl):\n",
        "        x_train,y_train = Data\n",
        "\n",
        "        t0_inter = time.time()\n",
        "        y_inter = modelinterpolation(x_train.reshape([batch_size,1,height,width,depth]))\n",
        "        t1_inter = time.time()\n",
        "        t0_inter1 = time.time()\n",
        "        y_inter = modelinterpolation(x_train.reshape([batch_size,1,height,width,depth]))\n",
        "        t1_inter1 = time.time()\n",
        "\n",
        "        Tinter += t1_inter - t0_inter\n",
        "        Tinter1 += t1_inter1 - t0_inter1\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz4-E5utQ9tf",
        "outputId": "76302e17-7955-4a09-9f28-4aa0e042a802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.491612195968628\n"
          ]
        }
      ],
      "source": [
        "print(Tinter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-1BScn38mhO"
      },
      "outputs": [],
      "source": [
        "\n",
        "import scipy as scp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiWQBUt2EYrt"
      },
      "outputs": [],
      "source": [
        "def SaveThings(filename,vec):\n",
        "  vec = vec[[2,1,0],:]\n",
        "\n",
        "  # (Optional) Calculate linearity score - how signifcant the found direction is\n",
        "  # Can be entered as weights parameter in visualization functions\n",
        "\n",
        "  # (Optional) Flip opposite vectors to face the same direction - easier visualization\n",
        "  flipOpposites = True\n",
        "  flipMask = vec[0,:] < 0\n",
        "  flipMask = np.array([flipMask,flipMask,flipMask])\n",
        "  vec[flipMask] = -vec[flipMask]\n",
        "\n",
        "  # Prepare mask - focus only on bright parts\n",
        "  bgMask = I_cut < 60\n",
        "\n",
        "  # Color representation of the directions in a volume\n",
        "  # rgba = volume.convertToFan(vec, halfSphere=flipOpposites, weights=None, mask=bgMask) #Old method (new name)\n",
        "  rgba = convertToIco(vec, weights=None, mask=bgMask) #New, bettter color scheme\n",
        "  saveRgbaVolume(rgba,savePath=filename+\".tiff\")\n",
        "\n",
        "\n",
        "  #%% alternative visualization - direction histogram visualized as a glyph\n",
        "\n",
        "  sph = orientationVec(vec.reshape(3,-1), fullSphere=True, weights=None) \n",
        "\n",
        "  H, el, az, binArea = histogram2d(sph,bins=[100,200],norm='prob_binArea', weights=None)\n",
        "\n",
        "  save_glyph(H,el,az,savePath=filename+\".vtk\", colorMap='Ico', flipColor=flipOpposites)\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh6dwrDP9i17"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tifffile\n",
        "import scmap\n",
        "\n",
        "#TODO: update documentation\n",
        "\n",
        "def cart2sph(cart):\n",
        "    \"\"\"Performs a conversion from carthesian to sperical coordinates, mimics matlab function with the same name\\n\n",
        "    Source:https://stackoverflow.com/questions/4116658/faster-numpy-cartesian-to-spherical-coordinate-conversion\\n\n",
        "    Params:\\n\n",
        "    cart - (3,n) np.array with cartesian coordinates\\n\n",
        "    returns: (radius, elevation,azimuth)\"\"\"\n",
        "    sph = np.zeros(cart.shape)\n",
        "    xy = cart[0,:]**2 + cart[1,:]**2\n",
        "    sph[0,:] = np.sqrt(xy + cart[2,:]**2)\n",
        "    # sph[:,1] = np.arctan2(np.sqrt(xy), cart[2,:]) # for elevation angle defined from Z-axis down\n",
        "    sph[1,:] = np.arctan2(cart[2,:], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
        "    sph[2,:] = np.arctan2(cart[1,:], cart[0,:])\n",
        "    return sph\n",
        "\n",
        "def orientationVec(vec,fullSphere=True, weights=None):\n",
        "    \"\"\"Get spherical orientation (azimuth, elevation) from collection of unit direction\n",
        "    vectors mapped either onto a sphere or half sphere with a given poleOrder.\\n\n",
        "    Params:\\n\n",
        "    vec - (3,n) np.array with unit vectors\\n\n",
        "    fullSphere - if True, returns complete sphere (redundant but nice looking), if False, returns half sphere\\n\n",
        "    weights - additional weights related to the vectors, carried over in case they need to be doubled when transitioning to fullSphere\n",
        "    \"\"\"\n",
        "    \n",
        "    sph = cart2sph(vec)\n",
        "    \n",
        "    if fullSphere == False:\n",
        "        # Flip directions onto half-sphere:\n",
        "        idxN = np.where(sph[2,:] < -np.pi/2);\n",
        "        idxP = np.where(sph[2,:] > np.pi/2);\n",
        "        \n",
        "        sph[2,idxN] = sph[2,idxN] + np.pi\n",
        "        sph[1,idxN] = -sph[1,idxN]\n",
        "        \n",
        "        sph[2,idxP] = sph[2,idxP] - np.pi\n",
        "        sph[1,idxP] = -sph[1,idxP]\n",
        "    if fullSphere == True:\n",
        "        sph2 = np.copy(sph)    \n",
        "        \n",
        "        sph2[1,:] = -sph2[1,:]\n",
        "        \n",
        "        idxN = np.where(sph2[2,:] < 0);\n",
        "        idxP = np.where(sph2[2,:] > 0);\n",
        "        \n",
        "        sph2[2,idxN] = sph2[2,idxN] + np.pi\n",
        "        sph2[2,idxP] = sph2[2,idxP] - np.pi\n",
        "        \n",
        "        sph = np.hstack((sph,sph2))\n",
        "        if weights is not None:\n",
        "            weights = np.hstack((weights,weights))\n",
        "        \n",
        "    if weights is None:\n",
        "        return sph\n",
        "    else:\n",
        "        return sph, weights\n",
        "    \n",
        "def histogram2d(sph:np.array, bins=[100,200], norm=None, weights=None):\n",
        "    \"\"\"Wrapper to the numpy histogram 2d function with some extra steps.\\n\n",
        "    Params:\\n\n",
        "    sph - (3,n) spherical coordinates\\n\n",
        "    bins - number of histogram bins in each direction\\n\n",
        "    norm - normalization type:\\n\n",
        "        'prob' - normalizes to 0-1 range\\n\n",
        "        'binArea' - corrects for the variable bin area\\n\n",
        "        'prob_binArea' - combines both\n",
        "    weights - additional weights for the histogram calculation (e.g. linearity score)\n",
        "    \"\"\"\n",
        "\n",
        "    H,el,az = np.histogram2d(sph[1,:],sph[2,:],bins=bins, weights=weights) \n",
        "\n",
        "    az_diff = az[1:]-az[:-1]\n",
        "    el_diff = np.sin(el[1:])-np.sin(el[:-1]) \n",
        "    el_dif_grid,az_dif_grid = np.meshgrid(el_diff,az_diff)\n",
        "    binArea = (el_dif_grid*az_dif_grid).transpose()\n",
        "    \n",
        "    if norm=='prob':\n",
        "        H = H/np.sum(H)\n",
        "    elif norm=='binArea':\n",
        "        H = H/binArea\n",
        "    elif norm=='prob_binArea':\n",
        "        H = H/binArea\n",
        "        H = H/np.sum(H)\n",
        "    else:\n",
        "        assert norm is None, f\"Wrong norm type: {norm}\"\n",
        "\n",
        "    return H, el, az, binArea\n",
        "\n",
        "def save_glyph(H,el,az,savePath,colorMap=None,flipColor=True):\n",
        "    \"\"\"Creates glyph-like mesh visualization from the 2d spherical coordinate eigenvector histogram\\n\n",
        "    Params\\n\n",
        "    H - histogram values\\n\n",
        "    el, az - binning limits in elevation and azimuth direction\\n\n",
        "    savePath - path where the .vtk file of the glyph surface should be saved.\\n\n",
        "    normDiv - normalization value, what to divide the histogram values by\\n\n",
        "    colorMap - if not None, saves color information in a glyph using a chosen colormap. Possible options: 'Fan' or 'Ico'\n",
        "    \"\"\"\n",
        "\n",
        "    el_center = (el[1:]+el[:-1])/2\n",
        "    az_center = (az[1:]+az[:-1])/2\n",
        "    el_center_grid,az_center_grid = np.meshgrid(el_center,az_center)\n",
        "    x = np.cos(el_center_grid)*np.cos(az_center_grid)\n",
        "    y = np.cos(el_center_grid)*np.sin(az_center_grid)\n",
        "    z = np.sin(el_center_grid)\n",
        "    XYZ = np.array([x,y,z])\n",
        "    if colorMap is not None:\n",
        "        XYZ_copy = np.copy(XYZ)\n",
        "        if flipColor:\n",
        "            # Flip to one half of the sphere, to have same colors on both sides\n",
        "            flipMask = XYZ_copy[0,:] < 0\n",
        "            flipMask = np.array([flipMask,flipMask,flipMask])\n",
        "            XYZ_copy[flipMask] = -XYZ_copy[flipMask]\n",
        "        if colorMap == 'Fan':\n",
        "            RGB = convertToFan(np.expand_dims(XYZ_copy,-1),halfSphere=flipColor)[:3,:,:,0]\n",
        "            RGB = 1-RGB\n",
        "        elif colorMap == 'Ico':\n",
        "            RGB = convertToIco(np.expand_dims(XYZ_copy,-1))[:3,:,:,0]\n",
        "            RGB = 1-RGB\n",
        "        else:\n",
        "            RGB = None\n",
        "    else:\n",
        "        RGB = None\n",
        "    XYZ = XYZ*H.T\n",
        "    \n",
        "    # Save as vtk surf\n",
        "    assert os.path.dirname(savePath) == '' or os.path.exists(os.path.dirname(savePath)), f\"Given path does not exist {savePath}\"\n",
        "    _, ext = os.path.splitext(savePath)\n",
        "    assert ext == '.vtk', f\"File extension ({ext}) is not .vtk\"\n",
        "\n",
        "    save_surf2vtk(savePath, XYZ, RGB)\n",
        "    \n",
        "    \n",
        "def save_surf2vtk(filename, XYZ, RGB=None):\n",
        "    '''  Writes a vtk file for a 3D surface with optional color information\n",
        "    '''\n",
        "    # Flip order to ZYX because paraview is weird\n",
        "    XYZ = XYZ[[2,1,0],:]\n",
        "    \n",
        "    indices = np.arange(XYZ[0,:,:].size).reshape(XYZ[0,:,:].shape)\n",
        "    vertices = np.moveaxis(np.reshape(XYZ,(3,-1)),0,-1)\n",
        "    lu = indices[:-1,:-1]\n",
        "    ru = indices[:-1,1:]\n",
        "    rb = indices[1:,1:]\n",
        "    lb = indices[1:,:-1]\n",
        "    faces = np.c_[4*np.ones(lu.size), lu.ravel(), ru.ravel(), rb.ravel(), lb.ravel()]\n",
        "    nf = faces.shape[0]\n",
        "\n",
        "    if RGB is not None:\n",
        "        colors = np.moveaxis(RGB.reshape((3,-1)),0,-1)\n",
        "     \n",
        "    with open(filename, 'w') as f:\n",
        "        f.write('# vtk DataFile Version 3.0\\n')\n",
        "        f.write('saved from matlab using save_surf2vtk\\n')\n",
        "        f.write('ASCII\\n')\n",
        "        f.write('DATASET POLYDATA\\n')\n",
        "        f.write('POINTS {} float\\n'.format(XYZ[0,:,:].size))\n",
        "        np.savetxt(f, vertices, fmt='%.5g', newline='\\n')\n",
        "        f.write('POLYGONS {} {}\\n'.format(nf,5*nf))\n",
        "        np.savetxt(f, faces, fmt='%d', newline='\\n')\n",
        "\n",
        "        if RGB is not None:\n",
        "            f.write('POINT_DATA {} \\n'.format(XYZ[0,:,:].size))\n",
        "            f.write('COLOR_SCALARS label 3\\n')\n",
        "            np.savetxt(f, colors, fmt='%.5g', newline='\\n')\n",
        "    \n",
        "\n",
        "def hsv2rgb3d(vol):\n",
        "    #https://www.had2know.org/technology/hsv-rgb-conversion-formula-calculator.html\n",
        "    M = vol[2,:,:,:]\n",
        "    m = M*(1-vol[1,:,:,:])\n",
        "    mod_res = ((vol[0,:,:,:]*180/(np.pi*60)))%2\n",
        "    z = (M-m)*(1-np.abs(mod_res-1))\n",
        "    \n",
        "    # Assuming H is in 0-180 range\n",
        "    R = np.zeros_like(vol[0,:,:,:])\n",
        "    G = np.zeros_like(vol[0,:,:,:])\n",
        "    B = np.zeros_like(vol[0,:,:,:])\n",
        "    \n",
        "    Hrange1 = vol[0,:,:,:] < np.pi/3\n",
        "    Hrange2 = np.bitwise_and(vol[0,:,:,:] >= np.pi/3, vol[0,:,:,:] < np.pi*2/3)\n",
        "    Hrange3 = np.bitwise_and(vol[0,:,:,:] >= np.pi*2/3, vol[0,:,:,:] < np.pi)\n",
        "    Hrange4 = np.bitwise_and(vol[0,:,:,:] >= np.pi, vol[0,:,:,:] < np.pi*4/3)\n",
        "    Hrange5 = np.bitwise_and(vol[0,:,:,:] >= np.pi*4/3, vol[0,:,:,:] < np.pi*5/3)\n",
        "    Hrange6 = vol[0,:,:,:] >= np.pi*5/3\n",
        "    \n",
        "    R[Hrange1] = M[Hrange1]\n",
        "    G[Hrange1] = (z+m)[Hrange1]\n",
        "    B[Hrange1] = m[Hrange1]\n",
        "\n",
        "    R[Hrange2] = (z+m)[Hrange2]\n",
        "    G[Hrange2] = M[Hrange2]\n",
        "    B[Hrange2] = m[Hrange2]\n",
        "\n",
        "    R[Hrange3] = m[Hrange3]\n",
        "    G[Hrange3] = M[Hrange3]\n",
        "    B[Hrange3] = (z+m)[Hrange3]\n",
        "    \n",
        "    R[Hrange4] = m[Hrange4]\n",
        "    G[Hrange4] = (z+m)[Hrange4]\n",
        "    B[Hrange4] = M[Hrange4]\n",
        "    \n",
        "    R[Hrange5] = (z+m)[Hrange5]\n",
        "    G[Hrange5] = m[Hrange5]\n",
        "    B[Hrange5] = M[Hrange5]\n",
        "    \n",
        "    R[Hrange6] = M[Hrange6]\n",
        "    G[Hrange6] = m[Hrange6]\n",
        "    B[Hrange6] = (z+m)[Hrange6]\n",
        "\n",
        "    return np.array([R,G,B])\n",
        "\n",
        "def convertToFan(vec, halfSphere=False, weights=None, mask=None):\n",
        "    \"\"\"Converts a volume of vectors to a volume of rgba values representing vector directions in a Fan scheme.\"\"\"\n",
        "\n",
        "    if halfSphere:\n",
        "        # Stretch artificially the x values to use all colors\n",
        "        fake_hsv = np.arctan2(vec[1,:,:],(vec[0,:,:]*2)-1)+np.pi\n",
        "    else:\n",
        "        fake_hsv = np.arctan2(vec[1,:,:],vec[0,:,:])+np.pi\n",
        "    fake_hsv = np.array([fake_hsv,np.ones_like(fake_hsv),np.ones_like(fake_hsv)])\n",
        "\n",
        "    fake_rgb = hsv2rgb3d(fake_hsv)\n",
        "    colormap_vol = (1-vec[2,:,:]**2)*fake_rgb + 0.5*(vec[2,:,:]**2)\n",
        "\n",
        "    colormap_vol = np.vstack((colormap_vol,np.ones_like(colormap_vol[0,:,:,:])[None,:]))\n",
        "\n",
        "    if weights is not None:\n",
        "        colormap_vol = colormap_vol*weights\n",
        "\n",
        "    if mask is not None:\n",
        "        mask_rgba = np.array((mask,mask,mask,mask))\n",
        "        colormap_vol[mask_rgba] = 0\n",
        "\n",
        "    return colormap_vol\n",
        "\n",
        "def convertToIco(vec,  weights=None, mask=None):\n",
        "    \"\"\"Converts a volume of vectors to a volume of rgba values representing vector directions in a Icosahedron scheme.\"\"\"\n",
        "\n",
        "    coloring = scmap.Ico() \n",
        "    vec_flip = np.moveaxis(vec.reshape(3,-1), 0,-1)\n",
        "    colormap_vol = coloring(vec_flip)\n",
        "    colormap_vol = np.moveaxis(colormap_vol,0,-1).reshape(vec.shape)\n",
        "\n",
        "    colormap_vol = np.vstack((colormap_vol,np.ones_like(colormap_vol[0,:,:,:])[None,:]))\n",
        "\n",
        "    if weights is not None:\n",
        "        colormap_vol = colormap_vol*weights\n",
        "\n",
        "    if mask is not None:\n",
        "        mask_rgba = np.array((mask,mask,mask,mask))\n",
        "        colormap_vol[mask_rgba] = 0\n",
        "\n",
        "    return colormap_vol\n",
        "\n",
        "def saveRgbaVolume(rgba,savePath=None):\n",
        "    \n",
        "    rgba = np.moveaxis(rgba,0,-1)\n",
        "    #  ParaView prefers to work with 8 bit uints\n",
        "    rgba = (rgba*255).astype(np.uint8)\n",
        "    # For some reason all colors are swapped in ParaView\n",
        "    rgba = 255-rgba\n",
        "    # ParaView needs a full range of values to work correctly\n",
        "    rgba[0,0,0,3] = 255\n",
        "    #Save as tiff\n",
        "    if savePath is not None:\n",
        "        assert os.path.dirname(savePath) == '' or os.path.exists(os.path.dirname(savePath)), f\"Given path does not exist {savePath}\"\n",
        "        _, ext = os.path.splitext(savePath)\n",
        "        assert ext == '.tiff', f\"File extension ({ext}) is not .tiff\"\n",
        "\n",
        "        tifffile.imwrite(savePath, rgba)\n",
        "\n",
        "\n",
        "def save_surf2vtk(filename, XYZ, RGB=None):\n",
        "    '''  Writes a vtk file for a 3D surface with optional color information\n",
        "    '''\n",
        "    # Flip order to ZYX because paraview is weird\n",
        "    XYZ = XYZ[[2,1,0],:]\n",
        "    \n",
        "    indices = np.arange(XYZ[0,:,:].size).reshape(XYZ[0,:,:].shape)\n",
        "    vertices = np.moveaxis(np.reshape(XYZ,(3,-1)),0,-1)\n",
        "    lu = indices[:-1,:-1]\n",
        "    ru = indices[:-1,1:]\n",
        "    rb = indices[1:,1:]\n",
        "    lb = indices[1:,:-1]\n",
        "    faces = np.c_[4*np.ones(lu.size), lu.ravel(), ru.ravel(), rb.ravel(), lb.ravel()]\n",
        "    nf = faces.shape[0]\n",
        "\n",
        "    if RGB is not None:\n",
        "        colors = np.moveaxis(RGB.reshape((3,-1)),0,-1)\n",
        "     \n",
        "    with open(filename, 'w') as f:\n",
        "        f.write('# vtk DataFile Version 3.0\\n')\n",
        "        f.write('saved from matlab using save_surf2vtk\\n')\n",
        "        f.write('ASCII\\n')\n",
        "        f.write('DATASET POLYDATA\\n')\n",
        "        f.write('POINTS {} float\\n'.format(XYZ[0,:,:].size))\n",
        "        np.savetxt(f, vertices, fmt='%.5g', newline='\\n')\n",
        "        f.write('POLYGONS {} {}\\n'.format(nf,5*nf))\n",
        "        np.savetxt(f, faces, fmt='%d', newline='\\n')\n",
        "\n",
        "        if RGB is not None:\n",
        "            f.write('POINT_DATA {} \\n'.format(XYZ[0,:,:].size))\n",
        "            f.write('COLOR_SCALARS label 3\\n')\n",
        "            np.savetxt(f, colors, fmt='%.5g', newline='\\n')\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J0dvpF67oYu"
      },
      "outputs": [],
      "source": [
        "x_train,y_train = next(iter(dl))\n",
        "I_cut = x_train[0,:,:,:].numpy()\n",
        "\n",
        "'''\n",
        "y_inter = modelinterpolation(x_train.reshape([batch_size,1,height,width,depth]))\n",
        "SaveThings('internew',y_inter[0,:,:,:,:].numpy())\n",
        "\n",
        "\n",
        "s = structure_tensor_3d(x_train[0,:,:,:],1/2,1)\n",
        "val,vec = eig_special_3d(s)\n",
        "SaveThings('structnew',vec)\n",
        "'''\n",
        "'''\n",
        "y_cart = modelcartesian(x_train.reshape([batch_size,1,height,width,depth]))\n",
        "SaveThings('cartnew1',y_cart[0,:,:,:,:].cpu().detach().numpy())\n",
        "'''\n",
        "\n",
        "\n",
        "y_pol = modelcartesian(x_train.reshape([batch_size,1,height,width,depth]))\n",
        "SaveThings('polnew2',y_pol[0,:,:,:,:].cpu().detach().numpy())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LZSwonz8ixn"
      },
      "outputs": [],
      "source": [
        "import volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OE-VYmtAbR-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}